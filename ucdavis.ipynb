{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "'''\n",
    "%pip install livelossplot\n",
    "%pip install torcheval\n",
    "%pip install torchmetrics\n",
    "'''\n",
    "import os\n",
    "os.chdir('/workplace/flowmind/')\n",
    "print(\"working in: \" + os.getcwd())\n",
    "\n",
    "#%run /workplace/flowmind/setup.py\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torchdata.datapipes.iter import FileLister\n",
    "\n",
    "# flowmind imports\n",
    "from flowmind.processing.dataloaders.common import FlowData\n",
    "from flowmind.processing.dataloaders.flowpic import Flowpic\n",
    "from flowmind.processing.dataloaders.common import (\n",
    "    DataPipeTransform,\n",
    "    FlowDataTransform,\n",
    "    datapipe_identity,\n",
    "    filter_csv_filename,\n",
    "    filter_min_flow_length,\n",
    "    flowdata_identity,\n",
    ")\n",
    "from flowmind.processing.scaler import Scaler\n",
    "from flowmind.contrastive import NTXentLoss\n",
    "\n",
    "# livelossplot imports\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "\n",
    "# others\n",
    "from datetime import timedelta\n",
    "import random\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "# sets csv limit\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# sets the device to use gpu if available, if not, use cpu\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- custom remap\n",
    "\n",
    "def remap_label(t: tuple[torch.Tensor, torch.Tensor, str], labels_d: dict[str, int]) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    return t[0], t[1], labels_d[t[2]]\n",
    "\n",
    "labels_ucdavis = [\n",
    "    \"google-doc\",\n",
    "    \"google-drive\",\n",
    "    \"google-music\",\n",
    "    \"google-search\",\n",
    "    \"youtube\",\n",
    "]\n",
    "\n",
    "labels_ucdavis_d = {label: i for i, label in enumerate(labels_ucdavis)}\n",
    "\n",
    "remap_label_ucdavis = partial(remap_label, labels_d=labels_ucdavis_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- custom dataloader creating function --\n",
    "\n",
    "def create_flowpic_dataloader(\n",
    "    dir_path: Path | str,\n",
    "    batch_size: int,\n",
    "    scaler: Scaler | None = None,\n",
    "    min_packets: int = 0,\n",
    "    time_bins: list = [0, 37.5, 75.0, 112.5, 150.0, 187.5, 225.0, 262.5, 300.0],\n",
    "    length_bins: list = [0, 187.5, 375.0, 562.5, 750.0, 937.5, 1125.0, 1312.5, 1500.0],\n",
    "    ppi_bins: list | None = None,\n",
    "    normalize: bool = False,\n",
    "    bidirectional: bool = True,\n",
    "    meta_key: str | list[str] | None = None,\n",
    "    dp_transform: DataPipeTransform = datapipe_identity,\n",
    "    flow_transform_1: FlowDataTransform = flowdata_identity, \n",
    "    flow_transform_2: FlowDataTransform = flowdata_identity, \n",
    "    num_workers: int = 0,\n",
    ") -> torch.utils.data.DataLoader:\n",
    "    \"\"\"Create torch DataLoader.\n",
    "       The dataloader creates 2d flowpic from ppi and transform them into tensors.\n",
    "\n",
    "    Args:\n",
    "        dir_path (Path | str): Directory with csvs.\n",
    "        batch_size (int): Batch size.\n",
    "        scaler (Mapping[str, Scaler] | None, optional): Data scaler to apply. Defaults to None.\n",
    "        min_packets (int, optional): Minimal flow lengths to include. Defaults to 0.\n",
    "        time_bins (list, optional): Time bins. Defaults to [0, 37.5, 75.0, 112.5, 150.0, 187.5, 225.0, 262.5, 300.0].\n",
    "        length_bins (list, optional): Packet size bins. Defaults to [0, 187.5, 375.0, 562.5, 750.0, 937.5, 1125.0, 1312.5, 1500.0].\n",
    "        ppi_bins (list | None, optional): PPI bins. Defaults to None.\n",
    "        normalize (bool, optional): Whether to normalize packets in bins instead of absolute counts. Defaults to False.\n",
    "        bidirectional (bool, optional): Whether to use bidirectional flowpic. Defaults to False.\n",
    "        meta_key (str | list[str] | None, optional): Target column name. Defaults to None.\n",
    "        dp_transform(DataPipeTransform, optional): Datapipe transform function. Defaults to identity.\n",
    "        flow_transform(FlowDataTransform, optional): Flow transform function. Defaults to identity.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.DataLoader: Torch DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    dp = (\n",
    "        FileLister(str(dir_path))\n",
    "        .filter(filter_csv_filename)\n",
    "        .sharding_filter() \n",
    "        .open_files() \n",
    "        .parse_csv_as_dict()\n",
    "        .filter(partial(filter_min_flow_length, threshold=min_packets)) \n",
    "        .map(lambda row: (row, row)) # each item in dp is (row, row)\n",
    "    )\n",
    "\n",
    "    dp = dp.map(\n",
    "        partial(\n",
    "            build_two_augmented_flows,\n",
    "            flow_transform_1=flow_transform_1,\n",
    "            flow_transform_2=flow_transform_2,\n",
    "            time_bins=time_bins,\n",
    "            length_bins=length_bins,\n",
    "            ppi_bins=ppi_bins,\n",
    "            normalize=normalize,\n",
    "            bidirectional=bidirectional,\n",
    "            meta_key=meta_key,\n",
    "            scaler=scaler,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dp = dp_transform(dp)\n",
    "\n",
    "    return torch.utils.data.DataLoader(dp.batch(batch_size).collate(), batch_size=None, num_workers=num_workers)\n",
    "\n",
    "def build_two_augmented_flows(\n",
    "    pair_of_rows: tuple[dict, dict],\n",
    "    flow_transform_1,\n",
    "    flow_transform_2,\n",
    "    time_bins,\n",
    "    length_bins,\n",
    "    ppi_bins,\n",
    "    normalize,\n",
    "    bidirectional,\n",
    "    meta_key,\n",
    "    scaler=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates (flowpic1, flowpic2, label) from (row1, row2).\n",
    "    \"\"\"\n",
    "    row1, row2 = pair_of_rows\n",
    "\n",
    "    # first flow\n",
    "    flow1 = Flowpic(\n",
    "        x=row1,\n",
    "        flow_transform=flow_transform_1,\n",
    "        time_bins=time_bins,\n",
    "        length_bins=length_bins,\n",
    "        ppi_bins=ppi_bins,\n",
    "        normalize=normalize,\n",
    "        bidirectional=bidirectional,\n",
    "        meta_key=meta_key,\n",
    "    )\n",
    "    out1 = flow1.export(scaler=scaler)  # => (tensor, label)\n",
    "\n",
    "    # second flow\n",
    "    flow2 = Flowpic(\n",
    "        x=row2,\n",
    "        flow_transform=flow_transform_2,\n",
    "        time_bins=time_bins,\n",
    "        length_bins=length_bins,\n",
    "        ppi_bins=ppi_bins,\n",
    "        normalize=normalize,\n",
    "        bidirectional=bidirectional,\n",
    "        meta_key=meta_key,\n",
    "    )\n",
    "    out2 = flow2.export(scaler=scaler)\n",
    "\n",
    "    fp1, label = out1    \n",
    "    fp2, _ = out2\n",
    "\n",
    "    return fp1, fp2, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- RTT augmentation --\n",
    "\n",
    "def augment_rtt(flow: FlowData, alpha_min: float = 0.5, alpha_max: float = 1.5) -> FlowData:\n",
    "    \"\"\"\n",
    "    Multiply arrival time of each packet by a factor alpha, where\n",
    "    alpha is chosen uniformly in [alpha_min, alpha_max]\n",
    "\n",
    "    Args\n",
    "        flow: original flow\n",
    "        alpha_min: min factor set to 0.5\n",
    "        alpha_max: max factor set to 1.5\n",
    "\n",
    "    Returns: \n",
    "        modified FlowData\n",
    "    \"\"\"\n",
    "    \n",
    "    if not flow.times:\n",
    "        return flow\n",
    "\n",
    "    # select random alpha \n",
    "    alpha = random.uniform(alpha_min, alpha_max)\n",
    "    init_time = flow.init_time\n",
    "\n",
    "    # convert time to float offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    \n",
    "    # RTT augmentation\n",
    "    offsets = [offset * alpha for offset in offsets]\n",
    "\n",
    "    # convert back\n",
    "    flow.times = [init_time + timedelta(seconds=offset) for offset in offsets]\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IAT augmentation --\n",
    "\n",
    "def augment_iat(flow: FlowData, b_min: float = -1.0, b_max: float = 1.0) -> FlowData:\n",
    "    '''\n",
    "    Add factor b to the arrival time of each packet, where\n",
    "    b is chosen uniformly in [b_min, b_max]\n",
    "\n",
    "    Args:\n",
    "        flow: original flow\n",
    "        b_min: min factor set to -1.0 \n",
    "        b_max: max factor set to 1.0\n",
    "\n",
    "    Returns: \n",
    "        modified FlowData\n",
    "    '''\n",
    "    \n",
    "    if not flow.times:\n",
    "        return flow\n",
    "    #print(\"original times: \", flow.times)\n",
    "\n",
    "    # calculate time\n",
    "    # FIXME: delete\n",
    "    #f_time = flow.times[-1] - flow.times[0]\n",
    "    #print(\"flow_time: \", f_time)\n",
    "    \n",
    "    # select random b \n",
    "    b = random.uniform(b_min, b_max)\n",
    "    init_time = flow.init_time\n",
    "\n",
    "    # convert time to float offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    \n",
    "    # IAT augmentation\n",
    "    offsets = [offset + b for offset in offsets]\n",
    "\n",
    "    # convert back\n",
    "    flow.times = [init_time + timedelta(seconds=offset) for offset in offsets]\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- packet loss augmentation --\n",
    "\n",
    "def packet_loss(flow: FlowData, dt: float = 0.1) -> FlowData:\n",
    "    '''\n",
    "    Packet loss augmentation - removing all packets within [t - dt, t + dt]\n",
    "    \n",
    "    Args:\n",
    "        flow: original flow\n",
    "        dt: delta t (interval length) set to 0.1\n",
    "    \n",
    "    Returns: \n",
    "        modified Flow with removed packets in that interval\n",
    "    ''' \n",
    "\n",
    "    if not flow.times:\n",
    "        return flow\n",
    "    \n",
    "    init_time = flow.init_time \n",
    "    \n",
    "    # conver to offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    flow_duration = offsets[-1] if offsets else 0.0\n",
    "\n",
    "    # zero or near-zero duration -> skip (would remove the whole flow)\n",
    "    # TODO: consider 2*dt\n",
    "    if flow_duration <= 0:\n",
    "        return flow\n",
    "\n",
    " \n",
    "    t = random.uniform(0, flow_duration)\n",
    "\n",
    "    # interval [t - dt, t + dt]\n",
    "    lower = t - dt\n",
    "    upper = t + dt\n",
    "\n",
    "    # lists for filtered packets\n",
    "    new_directions = []\n",
    "    new_lengths    = []\n",
    "    new_times      = []\n",
    "    new_push_flags = []\n",
    "\n",
    "    for offset, direction, length, time_val, push_flag in zip(offsets, flow.directions, flow.lengths, flow.times, flow.push_flags):\n",
    "        if not (lower <= offset <= upper):\n",
    "            new_directions.append(direction)\n",
    "            new_lengths.append(length)\n",
    "            new_times.append(time_val)\n",
    "            new_push_flags.append(push_flag)\n",
    "\n",
    "    # replace old lists with the fitered lists\n",
    "    flow.directions = new_directions\n",
    "    flow.lengths    = new_lengths\n",
    "    flow.times      = new_times\n",
    "    flow.push_flags = new_push_flags\n",
    "    flow.init_time  = flow.times[0] if flow.times else None\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TESTS --\n",
    "\n",
    "# dimensions validation\n",
    "def dim_val(dl_train: torch.utils.data.DataLoader) -> None:\n",
    "    print(\"dl train: \", type(dl_train), file=sys.stderr)\n",
    "    for (flowpic1, flowpic2, labels) in dl_train:\n",
    "        print(\"flowpic1\", type(flowpic1), file=sys.stderr)\n",
    "        print(\"flowpic2\", type(flowpic2), file=sys.stderr)\n",
    "        print(\"flowpic1 shape: \", flowpic1.shape, file=sys.stderr)\n",
    "        print(\"flowpic2 shape: \", flowpic2.shape, file=sys.stderr)\n",
    "        break    \n",
    "\n",
    "# print batch\n",
    "def print_batch(dl_train: torch.utils.data.DataLoader, type: str) -> None:\n",
    "    for batch in dl_train:\n",
    "        torch.set_printoptions(threshold=sys.maxsize)\n",
    "        print(\"printing \" + type + \" batch ...,\", file=sys.stderr)\n",
    "        print(batch, file=sys.stderr)\n",
    "        break\n",
    "    \n",
    "# debug batch    \n",
    "def debug_batch(dl: torch.utils.data.DataLoader) -> None:\n",
    "    for (flowpic1, flowpic2, labels) in dl:\n",
    "        print(\"flowpic1 type:\", type(flowpic1), file=sys.stderr)\n",
    "        print(\"flowpic2 type:\", type(flowpic2), file=sys.stderr)\n",
    "        print(\"label type:\", type(labels), file=sys.stderr)\n",
    "        \n",
    "        if isinstance(flowpic1, list):\n",
    "            print(f\"flowpic1 has {len(flowpic1)} items.\", file=sys.stderr)\n",
    "            print(\"Shapes of flowpic1 items:\", file=sys.stderr)\n",
    "            for i, fp in enumerate(flowpic1):\n",
    "                print(type(fp), file=sys.stderr)\n",
    "                print(f\"  Item {i}: {fp.shape}\", file=sys.stderr)\n",
    "                break\n",
    "\n",
    "        if isinstance(flowpic2, list):\n",
    "            print(f\"flowpic2 has {len(flowpic2)} items.\", file=sys.stderr)\n",
    "            print(\"Shapes of flowpic2 items:\", file=sys.stderr)\n",
    "            for i, fp in enumerate(flowpic2):\n",
    "                print(f\"  Item {i}: {fp.shape}\", file=sys.stderr)\n",
    "\n",
    "        print(\"labels:\", labels, file=sys.stderr)\n",
    "        break  # Just inspect the first batch\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATA LOADERS for Mirage22 --\n",
    "# dataloaders yield tuple (flowpic1, flowpic2, label)\n",
    "# using only 15 seconds of the flow\n",
    "# TODO: vyresit vyber augmentaci\n",
    "\n",
    "# 0 - debug prints are turned off\n",
    "# 1 - debug prints are turned on\n",
    "DEBUG = 0\n",
    "\n",
    "# dataloader used for training\n",
    "dl_train = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",    #TODO: pretraining nebo train.csv\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_rtt,\n",
    "    flow_transform_2=augment_rtt,\n",
    "    bidirectional = False,\n",
    "    min_packets=5,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_ucdavis).in_memory_cache(),\n",
    ")\n",
    "\n",
    "# dataloader used for validation\n",
    "dl_val = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/train.csv\",    # TODO: train vs val\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_rtt,\n",
    "    flow_transform_2=augment_rtt,\n",
    "    bidirectional = False,    \n",
    "    min_packets=5,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_ucdavis).in_memory_cache(),\n",
    ")\n",
    "\n",
    "# dataloader used for classification head\n",
    "dl_class = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,   \n",
    "    min_packets=5,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_ucdavis).in_memory_cache(),\n",
    ")\n",
    "\n",
    "# dataloader used for unseen data to test model\n",
    "dl_test = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/val.csv\",  # TODO: val??\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,   \n",
    "    min_packets=5,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_ucdavis).in_memory_cache(),\n",
    ")\n",
    "\n",
    "if DEBUG:    \n",
    "    #print(type(dl_train))\n",
    "    #dim_val(dl_train)\n",
    "    print_batch(dl_train, \"training\")\n",
    "    print_batch(dl_class, \"classification\")\n",
    "    #debug_batch(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- CNN architecture --     \n",
    "  \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(400, 120),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(120,120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(120,30),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.projection(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- fine tuning using linear classifier --\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, output_size: int, input_size=120):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training loops--\n",
    "\n",
    "def train(model, dataloader, optimizer, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Training loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        optimizer: chosen optimizer\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    # label not needed in -> _\n",
    "    for flowpic1, flowpic2, _ in dataloader:\n",
    "        flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z1 = model(flowpic1)\n",
    "        z2 = model(flowpic2)\n",
    "        \n",
    "        # contrastive loss\n",
    "        loss = contrastive_loss_fn(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batches += 1\n",
    "        \n",
    "    total_loss /= batches\n",
    "    log[\"loss\"] = total_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def val(model, dataloader, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Validation loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        batches = 0\n",
    "\n",
    "        # label not needed in -> _\n",
    "        for flowpic1, flowpic2, _ in dataloader:\n",
    "            flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "            z1 = model(flowpic1)\n",
    "            z2 = model(flowpic2)\n",
    "            \n",
    "            # contrastive loss\n",
    "            loss = contrastive_loss_fn(z1, z2)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batches += 1\n",
    "\n",
    "        total_loss /= batches\n",
    "        log[\"val_loss\"] = total_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def classification(CNN_model, MLP_model, dataloader, log, loss_fn, accuracy, optimizer):\n",
    "    '''\n",
    "    Classification loop\n",
    "\n",
    "    Args:\n",
    "        CNN_model: CNN model \n",
    "        MLP_model: MLP model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        log: for log collection\n",
    "        loss_fn: chosen loss function\n",
    "        accuracy: chosen model accuracy\n",
    "        optimizer: chosen optimizer\n",
    "\n",
    "    Returns:\n",
    "        classification loss \n",
    "    '''\n",
    "\n",
    "    # freeze the encoder\n",
    "    for param in CNN_model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # remove projection head\n",
    "    CNN_model.projection = nn.Sequential()\n",
    "    \n",
    "    # set models\n",
    "    CNN_model.eval()\n",
    "    MLP_model.train()\n",
    "\n",
    "    classification_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    for flowpic, _, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        flowpic, label = flowpic.to(device), label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = CNN_model.encoder(flowpic)\n",
    "        \n",
    "        y_pred = MLP_model(embeddings)\n",
    "\n",
    "        loss = loss_fn(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        classification_loss += loss.item()\n",
    "        batches += 1\n",
    "        \n",
    "        accuracy.update(y_pred, label)\n",
    "    \n",
    "    classification_loss /= batches\n",
    "\n",
    "    log[\"classification_loss\"] = classification_loss\n",
    "    log[\"accuracy\"] = accuracy.compute()\n",
    "        \n",
    "    accuracy.reset()\n",
    "\n",
    "    return classification_loss\n",
    "\n",
    "def testing(CNN_model, MLP_model, dataloader, log, loss_fn, accuracy):\n",
    "    '''\n",
    "    Testing loop\n",
    "\n",
    "    Args:\n",
    "        CNN_model: CNN model \n",
    "        MLP_model: MLP model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        log: for log collection\n",
    "        loss_fn: chosen loss function\n",
    "        accuracy: chosen model accuracy\n",
    "        optimizer: chosen optimizer\n",
    "\n",
    "    Returns:\n",
    "        training loss \n",
    "    '''\n",
    "\n",
    "    # freeze the encoder\n",
    "    for param in CNN_model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # set models\n",
    "    CNN_model.eval()\n",
    "    MLP_model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for flowpic_t, _, label in dataloader:\n",
    "            flowpic_t, label = flowpic_t.to(device), label.to(device)\n",
    "\n",
    "            embeddings = CNN_model.encoder(flowpic_t)\n",
    "            y_pred = MLP_model(embeddings)\n",
    "\n",
    "            loss = loss_fn(y_pred, label)\n",
    "            test_loss += loss.item()\n",
    "            batches += 1\n",
    "\n",
    "            accuracy.update(y_pred, label)\n",
    "    \n",
    "        test_loss /= batches\n",
    "    \n",
    "        log[\"test_loss\"] = test_loss\n",
    "        log[\"test_accuracy\"] = accuracy.compute()\n",
    "            \n",
    "        accuracy.reset()\n",
    "\n",
    "    return test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ucdavis dataset --\n",
    "\n",
    "classes = 5\n",
    "\n",
    "# CNN definition\n",
    "cnn_model = CNN()\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# NT-Xent loss function\n",
    "contrastive_loss_fn = NTXentLoss(temperature=0.07)\n",
    "\n",
    "cnn_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])\n",
    "\n",
    "# Linear classifier definition\n",
    "mlp_model = MLP(classes)\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "# loss function\n",
    "mlp_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mlp_accuracy = MulticlassAccuracy()\n",
    "\n",
    "mlp_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- traning CNN --\n",
    "\n",
    "for epoch in range(10):\n",
    "    log = {}\n",
    "    train_loss = train(cnn_model, dl_train, cnn_optimizer, contrastive_loss_fn, log)\n",
    "    val_loss = val(cnn_model, dl_val, contrastive_loss_fn, log)\n",
    "\n",
    "    cnn_liveloss.update(log)\n",
    "    cnn_liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training linear classifier --\n",
    "\n",
    "# set params for early stopping\n",
    "best_loss = float('inf')\n",
    "no_improvement = 0\n",
    "min_improvement = 0.001\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(20):\n",
    "    log = {}\n",
    "    classification_loss = classification(cnn_model, mlp_model, dl_class, log, mlp_loss_fn, mlp_accuracy, mlp_optimizer)   \n",
    "    test = testing(cnn_model, mlp_model, dl_test, log, mlp_loss_fn, mlp_accuracy)   \n",
    "\n",
    "    mlp_liveloss.update(log)\n",
    "    mlp_liveloss.send()\n",
    "\n",
    "    # early stopping\n",
    "    if best_loss - classification_loss > min_improvement:\n",
    "        best_loss = classification_loss\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "\n",
    "    if no_improvement >= patience:\n",
    "        print(\"Early stopping - epoch \", epoch)\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
