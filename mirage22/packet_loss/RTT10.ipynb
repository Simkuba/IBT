{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: Mirage22\n",
    "\n",
    "### Augmentations: \n",
    "- Packet loss\n",
    "- Flows with less than 10 packets removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "\n",
    "import os\n",
    "os.chdir('/workplace/flowmind/')\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "from flowmind.contrastive import NTXentLoss\n",
    "\n",
    "# livelossplot imports\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "\n",
    "# others\n",
    "from functools import partial\n",
    "\n",
    "# common imports\n",
    "os.chdir('/workplace/xcocek00/common/')\n",
    "from augmentations import augment_rtt\n",
    "os.chdir('/workplace/xcocek00/common/')\n",
    "from dataloader import create_flowpic_dataloader\n",
    "os.chdir('/workplace/xcocek00/common/')\n",
    "from nn import CNN, MLP\n",
    "\n",
    "# sets csv limit\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# sets the device to use gpu if available, if not, use cpu\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- custom remap_label function --\n",
    "\n",
    "def remap_label(t: tuple[torch.Tensor, torch.Tensor, str], labels_d: dict[str, int]) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    return t[0], t[1], labels_d[t[2]]\n",
    "\n",
    "labels_mirage22 = [\n",
    "    \"com.Slack\",\n",
    "    \"com.cisco.webex.meetings\",\n",
    "    \"com.discord\",\n",
    "    \"com.facebook.orca\",\n",
    "    \"com.google.android.apps.meetings\",\n",
    "    \"com.gotomeeting\",\n",
    "    \"com.microsoft.teams\",\n",
    "    \"com.skype.raider\",\n",
    "    \"us.zoom.videomeetings\",\n",
    "]\n",
    "\n",
    "\n",
    "labels_mirage22_d = {label: i for i, label in enumerate(labels_mirage22)}\n",
    "\n",
    "remap_label_mirage22 = partial(remap_label, labels_d=labels_mirage22_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATA LOADERS for Mirage22 --\n",
    "# dataloaders yield tuple (flowpic1, flowpic2, label)\n",
    "# using only 15 seconds of the flow\n",
    "\n",
    "# 0 - debug prints are turned off\n",
    "# 1 - debug prints are turned on\n",
    "DEBUG = 0\n",
    "\n",
    "# dataloader used for training\n",
    "dl_train = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage22/processed/splits-10/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_rtt,\n",
    "    flow_transform_2=augment_rtt,\n",
    "    bidirectional = False,\n",
    "    min_packets=10,\n",
    "    #min_length=25,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage22).in_memory_cache(),\n",
    ")\n",
    "\n",
    "# dataloader used for validation\n",
    "dl_val = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage22/processed/splits-10/val.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_2=augment_rtt,\n",
    "    flow_transform_1=augment_rtt,\n",
    "    bidirectional = False,    \n",
    "    min_packets=10,\n",
    "    #min_length=25,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage22).in_memory_cache(),\n",
    ")\n",
    "\n",
    "# dataloader used for classification head\n",
    "dl_class = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage22/processed/splits-10/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,   \n",
    "    min_packets=10,\n",
    "    #min_length=25,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage22).in_memory_cache(),\n",
    ")\n",
    "\n",
    "# dataloader used for unseen data to test model\n",
    "dl_test = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage22/processed/splits-10/test.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,   \n",
    "    min_packets=10,\n",
    "    #min_length=25,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage22).in_memory_cache(),\n",
    ")\n",
    "\n",
    "if DEBUG:    \n",
    "    #print(type(dl_train))\n",
    "    #dim_val(dl_train)\n",
    "    #print_batch(dl_train, \"training\")\n",
    "    #print_batch(dl_class, \"classification\")\n",
    "    #debug_batch(dl_train)\n",
    "    print(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training loops--\n",
    "\n",
    "def train(model, dataloader, optimizer, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Training loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        optimizer: chosen optimizer\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    # label not needed in -> _\n",
    "    for flowpic1, flowpic2, _ in dataloader:\n",
    "        flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z1 = model(flowpic1)\n",
    "        z2 = model(flowpic2)\n",
    "        \n",
    "        # contrastive loss\n",
    "        loss = contrastive_loss_fn(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batches += 1\n",
    "        \n",
    "    total_loss /= batches\n",
    "    log[\"loss\"] = total_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def val(model, dataloader, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Validation loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        batches = 0\n",
    "\n",
    "        # label not needed in -> _\n",
    "        for flowpic1, flowpic2, _ in dataloader:\n",
    "            flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "            z1 = model(flowpic1)\n",
    "            z2 = model(flowpic2)\n",
    "            \n",
    "            # contrastive loss\n",
    "            loss = contrastive_loss_fn(z1, z2)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batches += 1\n",
    "\n",
    "        total_loss /= batches\n",
    "        log[\"val_loss\"] = total_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def classification(CNN_model, MLP_model, dataloader, log, loss_fn, accuracy, optimizer):\n",
    "    '''\n",
    "    Classification loop\n",
    "\n",
    "    Args:\n",
    "        CNN_model: CNN model \n",
    "        MLP_model: MLP model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        log: for log collection\n",
    "        loss_fn: chosen loss function\n",
    "        accuracy: chosen model accuracy\n",
    "        optimizer: chosen optimizer\n",
    "\n",
    "    Returns:\n",
    "        classification loss \n",
    "    '''\n",
    "\n",
    "    # freeze the encoder\n",
    "    for param in CNN_model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # remove projection head\n",
    "    CNN_model.projection = nn.Sequential()\n",
    "    \n",
    "    # set models\n",
    "    CNN_model.eval()\n",
    "    MLP_model.train()\n",
    "\n",
    "    classification_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    for flowpic, _, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        flowpic, label = flowpic.to(device), label.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings = CNN_model.encoder(flowpic)\n",
    "        \n",
    "        y_pred = MLP_model(embeddings)\n",
    "\n",
    "        loss = loss_fn(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        classification_loss += loss.item()\n",
    "        batches += 1\n",
    "        \n",
    "        accuracy.update(y_pred, label)\n",
    "    \n",
    "    classification_loss /= batches\n",
    "\n",
    "    log[\"classification_loss\"] = classification_loss\n",
    "    log[\"accuracy\"] = accuracy.compute()\n",
    "        \n",
    "    accuracy.reset()\n",
    "\n",
    "    return classification_loss\n",
    "\n",
    "def testing(CNN_model, MLP_model, dataloader, log, loss_fn, accuracy):\n",
    "    '''\n",
    "    Testing loop\n",
    "\n",
    "    Args:\n",
    "        CNN_model: CNN model \n",
    "        MLP_model: MLP model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        log: for log collection\n",
    "        loss_fn: chosen loss function\n",
    "        accuracy: chosen model accuracy\n",
    "        optimizer: chosen optimizer\n",
    "\n",
    "    Returns:\n",
    "        training loss \n",
    "    '''\n",
    "\n",
    "    # freeze the encoder\n",
    "    for param in CNN_model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # set models\n",
    "    CNN_model.eval()\n",
    "    MLP_model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for flowpic_t, _, label in dataloader:\n",
    "            flowpic_t, label = flowpic_t.to(device), label.to(device)\n",
    "\n",
    "            embeddings = CNN_model.encoder(flowpic_t)\n",
    "            y_pred = MLP_model(embeddings)\n",
    "\n",
    "            loss = loss_fn(y_pred, label)\n",
    "            test_loss += loss.item()\n",
    "            batches += 1\n",
    "\n",
    "            accuracy.update(y_pred, label)\n",
    "    \n",
    "        test_loss /= batches\n",
    "    \n",
    "        log[\"model_loss\"] = test_loss\n",
    "        log[\"model_accuracy\"] = accuracy.compute()\n",
    "            \n",
    "        accuracy.reset()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Mirage22 dataset --\n",
    "\n",
    "mirage22_classes = 9\n",
    "\n",
    "# CNN definition\n",
    "cnn_model = CNN()\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# NT-Xent loss function\n",
    "contrastive_loss_fn = NTXentLoss(temperature=0.07)\n",
    "\n",
    "cnn_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])\n",
    "\n",
    "# Linear classifier definition\n",
    "mlp_model = MLP(mirage22_classes)\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "# loss function\n",
    "mlp_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mlp_accuracy = MulticlassAccuracy()\n",
    "\n",
    "mlp_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- traning CNN --\n",
    "\n",
    "for epoch in range(15):\n",
    "    log = {}\n",
    "    train_loss = train(cnn_model, dl_train, cnn_optimizer, contrastive_loss_fn, log)\n",
    "    val_loss = val(cnn_model, dl_val, contrastive_loss_fn, log)\n",
    "\n",
    "    cnn_liveloss.update(log)\n",
    "    cnn_liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training linear classifier --\n",
    "\n",
    "# set params for early stopping\n",
    "best_loss = float('inf')\n",
    "no_improvement = 0\n",
    "min_improvement = 0.001\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(20):\n",
    "    log = {}\n",
    "    classification_loss = classification(cnn_model, mlp_model, dl_class, log, mlp_loss_fn, mlp_accuracy, mlp_optimizer)   \n",
    "    test = testing(cnn_model, mlp_model, dl_test, log, mlp_loss_fn, mlp_accuracy)   \n",
    "\n",
    "    mlp_liveloss.update(log)\n",
    "    mlp_liveloss.send()\n",
    "\n",
    "    # early stopping\n",
    "    if best_loss - classification_loss > min_improvement:\n",
    "        best_loss = classification_loss\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "\n",
    "    if no_improvement >= patience:\n",
    "        print(\"Early stopping - epoch \", epoch)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model accuracy: \", mlp_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
