{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "'''\n",
    "%pip install livelossplot\n",
    "%pip install torcheval\n",
    "%pip install torchmetrics\n",
    "'''\n",
    "import os\n",
    "os.chdir('/workplace/flowmind/')\n",
    "print(\"working in: \" + os.getcwd())\n",
    "\n",
    "#%run /workplace/flowmind/setup.py\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torchdata.datapipes.iter import FileLister\n",
    "\n",
    "# flowmind imports\n",
    "from flowmind.processing.dataloaders.common import FlowData\n",
    "from flowmind.processing.dataloaders.flowpic import Flowpic\n",
    "from flowmind.processing.dataloaders.common import (\n",
    "    DataPipeTransform,\n",
    "    FlowData,\n",
    "    FlowDataTransform,\n",
    "    datapipe_identity,\n",
    "    filter_csv_filename,\n",
    "    filter_min_flow_length,\n",
    "    flowdata_identity,\n",
    ")\n",
    "from flowmind.processing.scaler import Scaler\n",
    "from flowmind.contrastive import NTXentLoss\n",
    "\n",
    "# livelossplot imports\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "\n",
    "# others\n",
    "from datetime import timedelta\n",
    "import random\n",
    "from functools import partial\n",
    "from typing import Callable\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "# sets csv limit\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# sets the device to use gpu if available, if not, use cpu\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- custom remap_label function --\n",
    "\n",
    "def remap_label(t: tuple[torch.Tensor, torch.Tensor, str], labels_d: dict[str, int]) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    return t[0], t[1], labels_d[t[2]]\n",
    "\n",
    "labels_mirage19 = [\n",
    "    \"com.joelapenna.foursquared\",\n",
    "    \"com.contextlogic.wish\",\n",
    "    \"com.pinterest\",\n",
    "    \"com.tripadvisor.tripadvisor\",\n",
    "    \"com.groupon\",\n",
    "    \"com.accuweather.android\",\n",
    "    \"com.waze\",\n",
    "    \"com.duolingo\",\n",
    "    \"com.viber.voip\",\n",
    "    \"com.facebook.katana\",\n",
    "    \"de.motain.iliga\",\n",
    "    \"it.subito\",\n",
    "    \"com.facebook.orca\",\n",
    "    \"com.dropbox.android\",\n",
    "    \"com.twitter.android\",\n",
    "    \"com.google.android.youtube\",\n",
    "    \"com.spotify.music\",\n",
    "    \"com.iconology.comics\",\n",
    "    \"com.trello\",\n",
    "    \"air.com.hypah.io.slither\",\n",
    "]\n",
    "\n",
    "\n",
    "labels_mirage22 = [\n",
    "    \"com.Slack\",\n",
    "    \"com.cisco.webex.meetings\",\n",
    "    \"com.discord\",\n",
    "    \"com.facebook.orca\",\n",
    "    \"com.google.android.apps.meetings\",\n",
    "    \"com.gotomeeting\",\n",
    "    \"com.microsoft.teams\",\n",
    "    \"com.skype.raider\",\n",
    "    \"us.zoom.videomeetings\",\n",
    "]\n",
    "\n",
    "\n",
    "labels_mirage19_d = {label: i for i, label in enumerate(labels_mirage19)}\n",
    "labels_mirage22_d = {label: i for i, label in enumerate(labels_mirage22)}\n",
    "\n",
    "remap_label_mirage19 = partial(remap_label, labels_d=labels_mirage19_d)\n",
    "remap_label_mirage22 = partial(remap_label, labels_d=labels_mirage22_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- custom dataloader creating function --\n",
    "\n",
    "def create_flowpic_dataloader(\n",
    "    dir_path: Path | str,\n",
    "    batch_size: int,\n",
    "    scaler: Scaler | None = None,\n",
    "    min_packets: int = 0,\n",
    "    time_bins: list = [0, 37.5, 75.0, 112.5, 150.0, 187.5, 225.0, 262.5, 300.0],\n",
    "    length_bins: list = [0, 187.5, 375.0, 562.5, 750.0, 937.5, 1125.0, 1312.5, 1500.0],\n",
    "    ppi_bins: list | None = None,\n",
    "    normalize: bool = False,\n",
    "    bidirectional: bool = True,\n",
    "    meta_key: str | list[str] | None = None,\n",
    "    dp_transform: DataPipeTransform = datapipe_identity,\n",
    "    flow_transform_1: FlowDataTransform = flowdata_identity, # prijima flow typu FlowData, vraci flow typu FlowData\n",
    "    flow_transform_2: FlowDataTransform = flowdata_identity, # prijima flow typu FlowData, vraci flow typu FlowData\n",
    "    num_workers: int = 0,\n",
    ") -> torch.utils.data.DataLoader:\n",
    "    \"\"\"Create torch DataLoader.\n",
    "       The dataloader creates 2d flowpic from ppi and transform them into tensors.\n",
    "\n",
    "    Args:\n",
    "        dir_path (Path | str): Directory with csvs.\n",
    "        batch_size (int): Batch size.\n",
    "        scaler (Mapping[str, Scaler] | None, optional): Data scaler to apply. Defaults to None.\n",
    "        min_packets (int, optional): Minimal flow lengths to include. Defaults to 0.\n",
    "        time_bins (list, optional): Time bins. Defaults to [0, 37.5, 75.0, 112.5, 150.0, 187.5, 225.0, 262.5, 300.0].\n",
    "        length_bins (list, optional): Packet size bins. Defaults to [0, 187.5, 375.0, 562.5, 750.0, 937.5, 1125.0, 1312.5, 1500.0].\n",
    "        ppi_bins (list | None, optional): PPI bins. Defaults to None.\n",
    "        normalize (bool, optional): Whether to normalize packets in bins instead of absolute counts. Defaults to False.\n",
    "        bidirectional (bool, optional): Whether to use bidirectional flowpic. Defaults to False.\n",
    "        meta_key (str | list[str] | None, optional): Target column name. Defaults to None.\n",
    "        dp_transform(DataPipeTransform, optional): Datapipe transform function. Defaults to identity.\n",
    "        flow_transform(FlowDataTransform, optional): Flow transform function. Defaults to identity.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.DataLoader: Torch DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    dp = (\n",
    "        FileLister(str(dir_path))\n",
    "        .filter(filter_csv_filename)\n",
    "        .sharding_filter() \n",
    "        .open_files() \n",
    "        .parse_csv_as_dict()\n",
    "        .filter(partial(filter_min_flow_length, threshold=min_packets)) \n",
    "        .map(lambda row: (row, row)) # each item in dp is (row, row)\n",
    "    )\n",
    "\n",
    "    dp = dp.map(\n",
    "        partial(\n",
    "            build_two_augmented_flows,\n",
    "            flow_transform_1=flow_transform_1,\n",
    "            flow_transform_2=flow_transform_2,\n",
    "            time_bins=time_bins,\n",
    "            length_bins=length_bins,\n",
    "            ppi_bins=ppi_bins,\n",
    "            normalize=normalize,\n",
    "            bidirectional=bidirectional,\n",
    "            meta_key=meta_key,\n",
    "            scaler=scaler,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    dp = dp_transform(dp)\n",
    "\n",
    "    return torch.utils.data.DataLoader(dp.batch(batch_size).collate(), batch_size=None, num_workers=num_workers)\n",
    "\n",
    "def build_two_augmented_flows(\n",
    "    pair_of_rows: tuple[dict, dict],\n",
    "    flow_transform_1: Callable[[FlowData], FlowData],\n",
    "    flow_transform_2: Callable[[FlowData], FlowData],\n",
    "    time_bins,\n",
    "    length_bins,\n",
    "    ppi_bins,\n",
    "    normalize,\n",
    "    bidirectional,\n",
    "    meta_key,\n",
    "    scaler=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates (flowpic1, flowpic2, label) from (row1, row2).\n",
    "    \"\"\"\n",
    "    row1, row2 = pair_of_rows\n",
    "\n",
    "    # first flow\n",
    "    flow1 = Flowpic(\n",
    "        x=row1,\n",
    "        flow_transform=flow_transform_1,\n",
    "        time_bins=time_bins,\n",
    "        length_bins=length_bins,\n",
    "        ppi_bins=ppi_bins,\n",
    "        normalize=normalize,\n",
    "        bidirectional=bidirectional,\n",
    "        meta_key=meta_key,\n",
    "    )\n",
    "    out1 = flow1.export(scaler=scaler)  # => (tensor, label)\n",
    "\n",
    "    # second flow\n",
    "    flow2 = Flowpic(\n",
    "        x=row2,\n",
    "        flow_transform=flow_transform_2,\n",
    "        time_bins=time_bins,\n",
    "        length_bins=length_bins,\n",
    "        ppi_bins=ppi_bins,\n",
    "        normalize=normalize,\n",
    "        bidirectional=bidirectional,\n",
    "        meta_key=meta_key,\n",
    "    )\n",
    "    out2 = flow2.export(scaler=scaler)\n",
    "\n",
    "    # parse out the (tensor, label)\n",
    "    if isinstance(out1, tuple):\n",
    "        fp1, label1 = out1\n",
    "    else:\n",
    "        fp1, label1 = out1, None\n",
    "    \n",
    "    fp2, _ = out2\n",
    "\n",
    "    return fp1, fp2, label1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- RTT augmentation --\n",
    "\n",
    "def augment_rtt(flow: FlowData, alpha_min: float = 0.5, alpha_max: float = 1.5) -> FlowData:\n",
    "    \"\"\"\n",
    "    Multiply arrival time of each packet by a factor alpha, where\n",
    "    alpha is chosen uniformly in [alpha_min, alpha_max]\n",
    "\n",
    "    Args\n",
    "        flow: original flow\n",
    "        alpha_min: min factor set to 0.5\n",
    "        alpha_max: max factor set to 1.5\n",
    "\n",
    "    Returns: \n",
    "        modified FlowData\n",
    "    \"\"\"\n",
    "    \n",
    "    if not flow.times:\n",
    "        return flow\n",
    "\n",
    "    # select random alpha \n",
    "    alpha = random.uniform(alpha_min, alpha_max)\n",
    "    init_time = flow.init_time\n",
    "\n",
    "    # convert time to float offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    \n",
    "    # RTT augmentation\n",
    "    offsets = [offset * alpha for offset in offsets]\n",
    "\n",
    "    # convert back\n",
    "    flow.times = [init_time + timedelta(seconds=offset) for offset in offsets]\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IAT augmentation --\n",
    "# FIXME: delete prints\n",
    "\n",
    "def augment_iat(flow: FlowData, b_min: float = -1.0, b_max: float = 1.0) -> FlowData:\n",
    "    '''\n",
    "    Add factor b to the arrival time of each packet, where\n",
    "    b is chosen uniformly in [b_min, b_max]\n",
    "\n",
    "    Args:\n",
    "        flow: original flow\n",
    "        b_min: min factor set to -1.0 \n",
    "        b_max: max factor set to 1.0\n",
    "\n",
    "    Returns: \n",
    "        modified FlowData\n",
    "    '''\n",
    "    \n",
    "    if not flow.times:\n",
    "        return flow\n",
    "    #print(\"original times: \", flow.times)\n",
    "\n",
    "    # select random b \n",
    "    b = random.uniform(b_min, b_max)\n",
    "    #print(\"printing b ... \", b)\n",
    "    init_time = flow.init_time\n",
    "\n",
    "    # convert time to float offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    \n",
    "    # IAT augmentation\n",
    "    offsets = [offset + b for offset in offsets]\n",
    "\n",
    "    # convert back\n",
    "    flow.times = [init_time + timedelta(seconds=offset) for offset in offsets]\n",
    "   #print(\"modified times: \", flow.times)\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- packet loss augmentation --\n",
    "\n",
    "def packet_loss(flow: FlowData, dt: float = 0.1) -> FlowData:\n",
    "    '''\n",
    "    Packet loss augmentation - removing all packets within [t - dt, t + dt]\n",
    "    \n",
    "    Args:\n",
    "        flow: original flow\n",
    "        dt: delta t (interval length) set to 0.1\n",
    "    \n",
    "    Returns: \n",
    "        modified Flow with removed packets in that interval\n",
    "    ''' \n",
    "\n",
    "    if not flow.times:\n",
    "        return flow\n",
    "    \n",
    "    init_time = flow.init_time \n",
    "    \n",
    "    # conver to offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    flow_duration = offsets[-1] if offsets else 0.0\n",
    "\n",
    "    # zero or near-zero duration -> skip (would remove the whole flow)\n",
    "    # TODO: consider 2*dt\n",
    "    if flow_duration <= 0:\n",
    "        return flow\n",
    "\n",
    " \n",
    "    t = random.uniform(0, flow_duration)\n",
    "\n",
    "    # interval [t - dt, t + dt]\n",
    "    lower = t - dt\n",
    "    upper = t + dt\n",
    "\n",
    "    # lists for filtered packets\n",
    "    new_directions = []\n",
    "    new_lengths    = []\n",
    "    new_times      = []\n",
    "    new_push_flags = []\n",
    "\n",
    "    for offset, direction, length, time_val, push_flag in zip(offsets, flow.directions, flow.lengths, flow.times, flow.push_flags):\n",
    "        if not (lower <= offset <= upper):\n",
    "            new_directions.append(direction)\n",
    "            new_lengths.append(length)\n",
    "            new_times.append(time_val)\n",
    "            new_push_flags.append(push_flag)\n",
    "\n",
    "    # replace old lists with the fitered lists\n",
    "    flow.directions = new_directions\n",
    "    flow.lengths    = new_lengths\n",
    "    flow.times      = new_times\n",
    "    flow.push_flags = new_push_flags\n",
    "    flow.init_time  = flow.times[0] if flow.times else None\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TESTS --\n",
    "\n",
    "# dimensions validation\n",
    "def dim_val(dl_train) -> None:\n",
    "    print(\"dl train: \", type(dl_train))\n",
    "    for (flowpic1, flowpic2, labels) in dl_train:\n",
    "        print(\"flowpic1\", type(flowpic1))\n",
    "        print(\"flowpic2\", type(flowpic2))\n",
    "        print(\"flowpic1 shape: \", flowpic1.shape)\n",
    "        print(\"flowpic2 shape: \", flowpic2.shape)\n",
    "        break    \n",
    "\n",
    "# print batch\n",
    "def print_batch(dl_train) -> None:\n",
    "    for batch in dl_train:\n",
    "        torch.set_printoptions(threshold=sys.maxsize)\n",
    "        print(batch)\n",
    "        break\n",
    "    \n",
    "# debug batch    \n",
    "def debug_batch(dl):\n",
    "    for (flowpic1, flowpic2, labels) in dl:\n",
    "        print(\"flowpic1 type:\", type(flowpic1))\n",
    "        print(\"flowpic2 type:\", type(flowpic2))\n",
    "        print(\"label type:\", type(labels))\n",
    "        \n",
    "        if isinstance(flowpic1, list):\n",
    "            print(f\"flowpic1 has {len(flowpic1)} items.\")\n",
    "            print(\"Shapes of flowpic1 items:\")\n",
    "            for i, fp in enumerate(flowpic1):\n",
    "                print(type(fp))\n",
    "                print(f\"  Item {i}: {fp.shape}\")\n",
    "                break\n",
    "\n",
    "        if isinstance(flowpic2, list):\n",
    "            print(f\"flowpic2 has {len(flowpic2)} items.\")\n",
    "            print(\"Shapes of flowpic2 items:\")\n",
    "            for i, fp in enumerate(flowpic2):\n",
    "                print(f\"  Item {i}: {fp.shape}\")\n",
    "\n",
    "        print(\"labels:\", labels)\n",
    "        break  # Just inspect the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATA LOADERS --\n",
    "# TODO: vyresit vyber augmentaci\n",
    "\n",
    "# 0 - debug prints are turned off\n",
    "# 1 - debug prints are turned on\n",
    "DEBUG = 0\n",
    "\n",
    "# dataloader yields tuple (flowpic, flowpic, label)\n",
    "# using the first 15 seconds of the flow\n",
    "dl_train = create_flowpic_dataloader(\n",
    "    #dir_path=\"/workplace/xcocek00/test_b.csv\",\n",
    "    dir_path=\"/workplace/datasets/mirage19/processed/splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_iat,\n",
    "    flow_transform_2=augment_iat,\n",
    "    bidirectional = False,\n",
    "    min_packets=15,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage19).in_memory_cache(),\n",
    ")\n",
    "dl_val = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage19/processed/splits/val.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_iat,\n",
    "    flow_transform_2=augment_iat,\n",
    "    bidirectional = False,    \n",
    "    min_packets=15,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage19).in_memory_cache(),\n",
    ")\n",
    "\n",
    "if DEBUG:    \n",
    "    #print(type(dl_train))\n",
    "    #dim_val(dl_train)\n",
    "    print_batch(dl_train)\n",
    "    #debug_batch(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- CNN architecture --\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # conv + pooling layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        # fully connected (fc) layers\n",
    "        self.fc1 = nn.Linear(400, 120) # 16*5*5 = 400 \n",
    "        self.fc2 = nn.Linear(120, 120)\n",
    "        self.fc3 = nn.Linear(120, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv + ReLU + pool 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # conv + ReLU + pool 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # flatten for fc layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # end of encoder f(·) -> h\n",
    "        h = F.relu(self.fc1(x))\n",
    "        \n",
    "        # projection head g(·) -> z\n",
    "        z = F.relu(self.fc2(h))   \n",
    "        z = self.fc3(z)\n",
    "        \n",
    "        # L2 normalize\n",
    "        #z = F.normalize(z, dim=1)\n",
    "        \n",
    "        '''\n",
    "        Returns:\n",
    "          h: 120-d representation\n",
    "          z: 30-d projection'\n",
    "        '''\n",
    "        return h, z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- fine tuning using linear classifier --\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, output_size: int, input_size=120):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training loops--\n",
    "\n",
    "def train(model, dataloader, optimizer, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Training loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        optimizer: chosen optimizer\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    # label not needed in -> _\n",
    "    for flowpic1, flowpic2, _ in dataloader:\n",
    "        flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass to get embeddings\n",
    "        _, z1 = model(flowpic1)  \n",
    "        _, z2 = model(flowpic2)  \n",
    "\n",
    "        # contrastive loss\n",
    "        loss = contrastive_loss_fn(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batches += 1\n",
    "        \n",
    "    avg_loss = total_loss / batches\n",
    "    log[\"loss\"] = avg_loss\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def val(model, dataloader, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Validation loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        batches = 0\n",
    "\n",
    "        # label not needed in -> _\n",
    "        for flowpic1, flowpic2, _ in dataloader:\n",
    "            flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "            # forward pass to get embeddings\n",
    "            _, z1 = model(flowpic1)  \n",
    "            _, z2 = model(flowpic2)  \n",
    "\n",
    "            # contrastive loss\n",
    "            loss = contrastive_loss_fn(z1, z2)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batches += 1\n",
    "\n",
    "        avg_loss = total_loss / batches\n",
    "        log[\"val_loss\"] = avg_loss\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def classification(CNN_model, MLP_model, dataloader, log, loss_fn, accuracy, optimizer):\n",
    "    '''\n",
    "    Classification loop\n",
    "\n",
    "    Args:\n",
    "        CNN_model: CNN model \n",
    "        MLP_model: MLP model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        log: for log collection\n",
    "        loss_fn: chosen loss function\n",
    "        accuracy: chosen model accuracy\n",
    "        optimizer: chosen optimizer\n",
    "\n",
    "    Returns:\n",
    "        classification loss \n",
    "    '''\n",
    "    \n",
    "    # freeze the encoder\n",
    "    for param in CNN_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # set models\n",
    "    CNN_model.eval()\n",
    "    MLP_model.train()\n",
    "\n",
    "    classification_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    for flowpic1, _, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        flowpic1, label = flowpic1.to(device), label.to(device)\n",
    "        \n",
    "        # forward pass to get embeddings\n",
    "        with torch.no_grad():\n",
    "            h, _ = CNN_model(flowpic1)  \n",
    "        \n",
    "        # use MLP for fine tuning\n",
    "        y_pred = MLP_model(h)\n",
    "        \n",
    "        loss = loss_fn(y_pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        classification_loss += loss.item()\n",
    "        batches += 1\n",
    "        accuracy.update(y_pred, label)\n",
    "    \n",
    "    classification_loss /= batches\n",
    "\n",
    "    log[\"classification_loss\"] = classification_loss\n",
    "    log[\"accuracy\"] = accuracy.compute()\n",
    "        \n",
    "    accuracy.reset()\n",
    "\n",
    "    return classification_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add more datasets\n",
    "mirage19_classes = 20\n",
    "\n",
    "# CNN definition\n",
    "cnn_model = CNN()\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# NT-Xent loss function\n",
    "contrastive_loss_fn = NTXentLoss(temperature=0.07)\n",
    "\n",
    "cnn_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])\n",
    "\n",
    "# Linear classifier definition\n",
    "mlp_model = MLP(mirage19_classes)\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "# loss function\n",
    "mlp_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mlp_accuracy = MulticlassAccuracy()\n",
    "\n",
    "mlp_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- traning CNN --\n",
    "\n",
    "for epoch in range(15):\n",
    "    log = {}\n",
    "    train_loss = train(cnn_model, dl_train, cnn_optimizer, contrastive_loss_fn, log)\n",
    "    val_loss = val(cnn_model, dl_val, contrastive_loss_fn, log)\n",
    "\n",
    "    cnn_liveloss.update(log)\n",
    "    cnn_liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training linear classifier --\n",
    "# TODO: add test set\n",
    "\n",
    "# set params for early stopping\n",
    "best_loss = float('inf')\n",
    "no_improvement = 0\n",
    "min_improvement = 0.001\n",
    "patience = 5\n",
    "\n",
    "for epoch in range(10):\n",
    "    log = {}\n",
    "    classification_loss = classification(cnn_model, mlp_model, dl_train, log, mlp_loss_fn, mlp_accuracy, mlp_optimizer)    \n",
    "\n",
    "    mlp_liveloss.update(log)\n",
    "    mlp_liveloss.send()\n",
    "\n",
    "    print(log)\n",
    "\n",
    "    # early stopping\n",
    "    '''\n",
    "    if best_loss - classification_loss > min_improvement:\n",
    "        best_loss = classification_loss\n",
    "        no_improvement = 0\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "\n",
    "    if no_improvement >= patience:\n",
    "        print(\"Early stopping ...\")\n",
    "        break\n",
    "    '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
