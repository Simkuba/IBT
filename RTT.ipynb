{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS --\n",
    "'''\n",
    "%pip install livelossplot\n",
    "%pip install torcheval\n",
    "%pip install torchmetrics\n",
    "'''\n",
    "import os\n",
    "os.chdir('/workplace/flowmind/')\n",
    "print(\"working in: \" + os.getcwd())\n",
    "\n",
    "#%run /workplace/flowmind/setup.py\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.functional as FM\n",
    "import torchvision.transforms as T\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "\n",
    "# flowmind imports\n",
    "#from flowmind.processing.dataloaders.flowpic import create_flowpic_dataloader \n",
    "#from flowmind.datasets.mirage import remap_label_mirage19\n",
    "from flowmind.processing.dataloaders.common import FlowData\n",
    "\n",
    "# livelossplot imports\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "\n",
    "# others\n",
    "from datetime import timedelta\n",
    "import random\n",
    "\n",
    "os.chdir('/workplace/xcocek00/')\n",
    "print(\"working in: \" + os.getcwd())\n",
    "from flowpic import create_flowpic_dataloader\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "# sets the device to use gpu if available, if not, use cpu\n",
    "device = torch.device(f\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- RTT augmentation --\n",
    "\n",
    "def augment_rtt(flow: FlowData, alpha_min: float = 0.5, alpha_max: float = 10.5) -> FlowData:\n",
    "    \"\"\"\n",
    "    Multiply arrival time of each packet by a factor alpha, where\n",
    "    alpha is chosen uniformly in [alpha_min, alpha_max]\n",
    "\n",
    "    Args\n",
    "        flow: original flow\n",
    "        alpha_min: min factor set to 0.5\n",
    "        alpha_max: max factor set to 1.5\n",
    "\n",
    "    Returns: \n",
    "        modified FlowData\n",
    "    \"\"\"\n",
    "    \n",
    "    if not flow.times:\n",
    "        return flow\n",
    "\n",
    "    # select random alpha \n",
    "    alpha = random.uniform(alpha_min, alpha_max)\n",
    "    init_time = flow.init_time\n",
    "\n",
    "    # convert time to float offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    \n",
    "    # RTT augmentation\n",
    "    offsets = [offset * alpha for offset in offsets]\n",
    "\n",
    "    # convert back\n",
    "    flow.times = [init_time + timedelta(seconds=offset) for offset in offsets]\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IAT augmentation --\n",
    "\n",
    "def augment_iat(flow: FlowData, b_min: float = -1.0, b_max: float = 1.0) -> FlowData:\n",
    "    '''\n",
    "    Add factor b to the arrival time of each packet, where\n",
    "    b is chosen uniformly in [b_min, b_max]\n",
    "\n",
    "    Args:\n",
    "        flow: original flow\n",
    "        b_min: min factor set to -1.0 \n",
    "        b_max: max factor set to 1.0\n",
    "\n",
    "    Returns: \n",
    "        modified FlowData\n",
    "    '''\n",
    "    \n",
    "    if not flow.times:\n",
    "        return flow\n",
    "\n",
    "    # select random b \n",
    "    b = random.uniform(b_min, b_max)\n",
    "    init_time = flow.init_time\n",
    "\n",
    "    # convert time to float offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    \n",
    "    # IAT augmentation\n",
    "    offsets = [offset + b for offset in offsets]\n",
    "\n",
    "    # convert back\n",
    "    flow.times = [init_time + timedelta(seconds=offset) for offset in offsets]\n",
    "\n",
    "    return flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- packet loss augmentation --\n",
    "\n",
    "def packet_loss(flow: FlowData, dt: float = 0.1) -> FlowData:\n",
    "    '''\n",
    "    Packet loss augmentation - removing all packets within [t - dt, t + dt]\n",
    "    \n",
    "    Args:\n",
    "        flow: original flow\n",
    "        dt: delta t (interval length) set to 0.1\n",
    "    \n",
    "    Returns: \n",
    "        modified Flow with removed packets in that interval\n",
    "    ''' \n",
    "\n",
    "    if not flow.times:\n",
    "        return flow\n",
    "    \n",
    "    init_time = flow.init_time \n",
    "    \n",
    "    # conver to offset\n",
    "    offsets = [(t - init_time).total_seconds() for t in flow.times]\n",
    "    flow_duration = offsets[-1] if offsets else 0.0\n",
    "\n",
    "    # zero or near-zero duration -> skip (would remove the whole flow)\n",
    "    # TODO: consider 2*dt\n",
    "    if flow_duration <= 0:\n",
    "        return flow\n",
    "\n",
    " \n",
    "    t = random.uniform(0, flow_duration)\n",
    "\n",
    "    # interval [t - dt, t + dt]\n",
    "    lower = t - dt\n",
    "    upper = t + dt\n",
    "\n",
    "    # lists for filtered packets\n",
    "    new_directions = []\n",
    "    new_lengths    = []\n",
    "    new_times      = []\n",
    "    new_push_flags = []\n",
    "\n",
    "    for offset, direction, length, time_val, push_flag in zip(offsets, flow.directions, flow.lengths, flow.times, flow.push_flags):\n",
    "        if not (lower <= offset <= upper):\n",
    "            new_directions.append(direction)\n",
    "            new_lengths.append(length)\n",
    "            new_times.append(time_val)\n",
    "            new_push_flags.append(push_flag)\n",
    "\n",
    "    # replace old lists with the fitered lists\n",
    "    flow.directions = new_directions\n",
    "    flow.lengths    = new_lengths\n",
    "    flow.times      = new_times\n",
    "    flow.push_flags = new_push_flags\n",
    "    flow.init_time  = flow.times[0] if flow.times else None\n",
    "\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- TESTS --\n",
    "\n",
    "# dimensions validation\n",
    "def dim_val(dl_train) -> None:\n",
    "    print(\"dl train: \", type(dl_train))\n",
    "    for (flowpic1, flowpic2, labels) in dl_train:\n",
    "        print(\"flowpic1\", type(flowpic1))\n",
    "        print(\"flowpic2\", type(flowpic2))\n",
    "        print(\"flowpic1 shape: \", flowpic1.shape)\n",
    "        print(\"flowpic2 shape: \", flowpic2.shape)\n",
    "        break    \n",
    "\n",
    "# print batch\n",
    "def print_batch(dl_train) -> None:\n",
    "    for batch in dl_train:\n",
    "        torch.set_printoptions(threshold=sys.maxsize)\n",
    "        print(batch)\n",
    "        break\n",
    "    \n",
    "# debug batch    \n",
    "def debug_batch(dl):\n",
    "    for (flowpic1, flowpic2, labels) in dl:\n",
    "        print(\"flowpic1 type:\", type(flowpic1))\n",
    "        print(\"flowpic2 type:\", type(flowpic2))\n",
    "        print(\"label type:\", type(labels))\n",
    "        \n",
    "        if isinstance(flowpic1, list):\n",
    "            print(f\"flowpic1 has {len(flowpic1)} items.\")\n",
    "            print(\"Shapes of flowpic1 items:\")\n",
    "            for i, fp in enumerate(flowpic1):\n",
    "                print(type(fp))\n",
    "                print(f\"  Item {i}: {fp.shape}\")\n",
    "                break\n",
    "\n",
    "        if isinstance(flowpic2, list):\n",
    "            print(f\"flowpic2 has {len(flowpic2)} items.\")\n",
    "            print(\"Shapes of flowpic2 items:\")\n",
    "            for i, fp in enumerate(flowpic2):\n",
    "                print(f\"  Item {i}: {fp.shape}\")\n",
    "\n",
    "        print(\"labels:\", labels)\n",
    "        break  # Just inspect the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- custom remap_label function --\n",
    "from functools import partial\n",
    "\n",
    "def remap_label(t: tuple[torch.Tensor, torch.Tensor, str], labels_d: dict[str, int]) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    return t[0], t[1], labels_d[t[2]]\n",
    "\n",
    "labels_mirage19 = [\n",
    "    \"com.joelapenna.foursquared\",\n",
    "    \"com.contextlogic.wish\",\n",
    "    \"com.pinterest\",\n",
    "    \"com.tripadvisor.tripadvisor\",\n",
    "    \"com.groupon\",\n",
    "    \"com.accuweather.android\",\n",
    "    \"com.waze\",\n",
    "    \"com.duolingo\",\n",
    "    \"com.viber.voip\",\n",
    "    \"com.facebook.katana\",\n",
    "    \"de.motain.iliga\",\n",
    "    \"it.subito\",\n",
    "    \"com.facebook.orca\",\n",
    "    \"com.dropbox.android\",\n",
    "    \"com.twitter.android\",\n",
    "    \"com.google.android.youtube\",\n",
    "    \"com.spotify.music\",\n",
    "    \"com.iconology.comics\",\n",
    "    \"com.trello\",\n",
    "    \"air.com.hypah.io.slither\",\n",
    "]\n",
    "\n",
    "\n",
    "labels_mirage22 = [\n",
    "    \"com.Slack\",\n",
    "    \"com.cisco.webex.meetings\",\n",
    "    \"com.discord\",\n",
    "    \"com.facebook.orca\",\n",
    "    \"com.google.android.apps.meetings\",\n",
    "    \"com.gotomeeting\",\n",
    "    \"com.microsoft.teams\",\n",
    "    \"com.skype.raider\",\n",
    "    \"us.zoom.videomeetings\",\n",
    "]\n",
    "\n",
    "\n",
    "labels_mirage19_d = {label: i for i, label in enumerate(labels_mirage19)}\n",
    "labels_mirage22_d = {label: i for i, label in enumerate(labels_mirage22)}\n",
    "\n",
    "remap_label_mirage19 = partial(remap_label, labels_d=labels_mirage19_d)\n",
    "remap_label_mirage22 = partial(remap_label, labels_d=labels_mirage22_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- DATA LOADERS --\n",
    "# TODO: vyresit vyber augmentaci\n",
    "\n",
    "# 0 - debug prints are turned off\n",
    "# 1 - debug prints are turned on\n",
    "DEBUG = 0\n",
    "\n",
    "# dataloader yields tuple (flowpic, flowpic, label)\n",
    "dl_train = create_flowpic_dataloader(\n",
    "    #dir_path=\"/workplace/xcocek00/test_b.csv\",\n",
    "    dir_path=\"/workplace/datasets/mirage19/processed/splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (300 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_rtt,\n",
    "    flow_transform_2=augment_rtt,\n",
    "    bidirectional = False,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage19).in_memory_cache(),\n",
    ")\n",
    "dl_val = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage19/processed/splits/val.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",\n",
    "    time_bins = [i * (300 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    flow_transform_1=augment_rtt,\n",
    "    flow_transform_2=augment_rtt,\n",
    "    bidirectional = False,\n",
    "    dp_transform=lambda dp: dp.map(remap_label_mirage19).in_memory_cache(),\n",
    ")\n",
    "\n",
    "if DEBUG:    \n",
    "    #print(type(dl_train))\n",
    "    dim_val(dl_train)\n",
    "    #print_batch(dl_train)\n",
    "    #debug_batch(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- CNN architecture --\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # conv + pooling layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "\n",
    "        # fully connected (fc) layers\n",
    "        self.fc1 = nn.Linear(400, 120) # 16*5*5 = 400 \n",
    "        self.fc2 = nn.Linear(120, 120)\n",
    "        self.fc3 = nn.Linear(120, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv + ReLU + pool 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # conv + ReLU + pool 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # flatten for fc layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # end of encoder f(·) -> h\n",
    "        h = F.relu(self.fc1(x))\n",
    "        \n",
    "        # projection head g(·) -> z\n",
    "        z = F.relu(self.fc2(h))   \n",
    "        z = self.fc3(z)\n",
    "        \n",
    "        # L2 normalize\n",
    "        z = F.normalize(z, dim=1)\n",
    "        \n",
    "        '''\n",
    "        Returns:\n",
    "          h: 120-d representation\n",
    "          z: 30-d projection'\n",
    "        '''\n",
    "        return h, z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- fine tuning using linear classifier --\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, output_size: int, input_size=120):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training loops--\n",
    "# FIXME: delete custom acc\n",
    "\n",
    "def train(model, dataloader, optimizer, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Training loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        optimizer: chosen optimizer\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    batches = 0\n",
    "    acc_total = 0.0\n",
    "\n",
    "    # label not needed in -> _\n",
    "    for flowpic1, flowpic2, _ in dataloader:\n",
    "        flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass to get embeddings\n",
    "        _, z1 = model(flowpic1)  \n",
    "        _, z2 = model(flowpic2)  \n",
    "\n",
    "        # contrastive loss\n",
    "        loss = contrastive_loss_fn(z1, z2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        batches += 1\n",
    "        \n",
    "        batch_acc = contrastive_accuracy(z1, z2, temperature=0.07)\n",
    "        acc_total += batch_acc.item()\n",
    "\n",
    "    avg_loss = total_loss / batches\n",
    "    avg_acc = acc_total / batches\n",
    "    log[\"loss\"] = avg_loss\n",
    "    #log[\"accuracy\"] = avg_acc\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def val(model, dataloader, contrastive_loss_fn, log):\n",
    "    '''\n",
    "    Validation loop\n",
    "\n",
    "    Args:\n",
    "        model: CNN model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        contrastive_loss_fn: contrastive loss function (NT-Xent)\n",
    "        log: for log collection\n",
    "\n",
    "    Returns:\n",
    "        Avarage loss \n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        batches = 0\n",
    "        acc_total = 0.0\n",
    "\n",
    "        # label not needed in -> _\n",
    "        for flowpic1, flowpic2, _ in dataloader:\n",
    "            flowpic1, flowpic2 = flowpic1.to(device), flowpic2.to(device)\n",
    "\n",
    "            # forward pass to get embeddings\n",
    "            _, z1 = model(flowpic1)  \n",
    "            _, z2 = model(flowpic2)  \n",
    "\n",
    "            # contrastive loss\n",
    "            loss = contrastive_loss_fn(z1, z2)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            batches += 1\n",
    "            \n",
    "            batch_acc = contrastive_accuracy(z1, z2, temperature=0.07)\n",
    "            acc_total += batch_acc.item()\n",
    "\n",
    "        avg_loss = total_loss / batches\n",
    "        avg_acc = acc_total / batches\n",
    "        log[\"val_loss\"] = avg_loss\n",
    "        #log[\"val_accuracy\"] = avg_acc\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def classification(CNN_model, MLP_model, dataloader, log, loss_fn, accuracy, optimizer):\n",
    "    '''\n",
    "    Classification loop\n",
    "\n",
    "    Args:\n",
    "        CNN_model: CNN model \n",
    "        MLP_model: MLP model\n",
    "        dataloader: pytorch dataloader created by create_flowpic_dataloader function\n",
    "        log: for log collection\n",
    "        loss_fn: chosen loss function\n",
    "        accuracy: chosen model accuracy\n",
    "        optimizer: chosen optimizer\n",
    "\n",
    "    Returns:\n",
    "        classification loss \n",
    "    '''\n",
    "\n",
    "    # freeze the encoder\n",
    "    for param in CNN_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # set models\n",
    "    CNN_model.eval()\n",
    "    MLP_model.train()\n",
    "\n",
    "    classification_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    for flowpic1, flowpic2, label in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        flowpic1, flowpic2, label = flowpic1.to(device), flowpic2.to(device), label.to(device)\n",
    "        \n",
    "        # forward pass to get embeddings\n",
    "        with torch.no_grad():\n",
    "            h, _ = CNN_model(flowpic1)  \n",
    "            _, _ = CNN_model(flowpic2)  \n",
    "        \n",
    "        # use MLP for fine tuning\n",
    "        y = MLP_model(h)\n",
    "        \n",
    "        loss = loss_fn(y, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        classification_loss += loss.item()\n",
    "        batches += 1\n",
    "        accuracy.update(y, label)\n",
    "    \n",
    "    classification_loss /= batches\n",
    "        \n",
    "    log[\"classification_loss\"] = classification_loss\n",
    "    log[\"accuracy\"] = accuracy.compute()\n",
    "        \n",
    "    accuracy.reset()\n",
    "\n",
    "    return classification_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- loss function --\n",
    "\n",
    "def nt_xent_loss(z1: torch.Tensor, z2: torch.Tensor, temperature: float = 0.07) -> torch.Tensor:\n",
    "    '''\n",
    "    NT-Xent (Normalized Temperature-Scaled Cross-Entropy) loss function\n",
    "    \n",
    "    Args:\n",
    "        z1: tensor \n",
    "        z2: tensor \n",
    "        temperature: scaling factor\n",
    "    \n",
    "    Returns:\n",
    "        A scalar loss value\n",
    "    '''\n",
    "    \n",
    "    batch_size = z1.shape[0]\n",
    "    \n",
    "    # concatenate embeddings -> shape [2N, embed_dim]\n",
    "    z = torch.cat([z1, z2], dim=0)\n",
    "    \n",
    "    # cosine similarity matrix scaled by temperature\n",
    "    sim_matrix = torch.matmul(z, z.T) / temperature\n",
    "    \n",
    "    # mask to remove self-similarities (diagonal entries)\n",
    "    diag_mask = torch.eye(2 * batch_size, dtype=torch.bool, device=z.device)\n",
    "    sim_matrix.masked_fill_(diag_mask, -float('inf'))\n",
    "    \n",
    "    # for each i the positive example is:\n",
    "    # - i in [0, N-1] then positive is: i + N\n",
    "    # - i in [N, 2N-1] then positive is: i - N\n",
    "    positives = torch.cat([\n",
    "        torch.arange(batch_size, 2 * batch_size),\n",
    "        torch.arange(0, batch_size)\n",
    "    ], dim=0).to(z.device)\n",
    "    \n",
    "    # cross entropy loss\n",
    "    loss = F.cross_entropy(sim_matrix, positives)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add more datasets\n",
    "mirage19_classes = 20\n",
    "\n",
    "# CNN definition\n",
    "cnn_model = CNN()\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001)\n",
    "\n",
    "# NT-Xent loss function\n",
    "contrastive_loss_fn = nt_xent_loss\n",
    "\n",
    "cnn_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])\n",
    "\n",
    "# Linear classifier definition\n",
    "mlp_model = MLP(mirage19_classes)\n",
    "mlp_model = mlp_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "mlp_optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.01)\n",
    "\n",
    "# loss function\n",
    "mlp_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "mlp_accuracy = MulticlassAccuracy()\n",
    "\n",
    "mlp_liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6, 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- traning CNN --\n",
    "\n",
    "for epoch in range(10):\n",
    "    log = {}\n",
    "    train_loss = train(cnn_model, dl_train, cnn_optimizer, contrastive_loss_fn, log)\n",
    "    val_loss = val(cnn_model, dl_val, contrastive_loss_fn, log)\n",
    "\n",
    "    cnn_liveloss.update(log)\n",
    "    cnn_liveloss.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- training linear classifier --\n",
    "# TODO: add test set\n",
    "\n",
    "for epoch in range(5):\n",
    "    log = {}\n",
    "    classification_loss = classification(cnn_model, mlp_model, dl_train, log, mlp_loss_fn, mlp_accuracy, mlp_optimizer)\n",
    "\n",
    "    mlp_liveloss.update(log)\n",
    "    mlp_liveloss.send()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
