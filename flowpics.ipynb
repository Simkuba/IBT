{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc817625",
   "metadata": {},
   "source": [
    "# Visual reprezentation of FlowPics \n",
    "#### Author: Jakub Čoček (xcocek00)\n",
    "\n",
    "Creates visual reprezentation of FlowPics with and without augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cd996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- IMPORTS --\n",
    "\n",
    "import os \n",
    "os.chdir('/workplace/xcocek00/common/')\n",
    "from dataloader import create_flowpic_dataloader\n",
    "\n",
    "os.chdir('/workplace/xcocek00/common/')\n",
    "from augmentations import (\n",
    "    augment_iat,\n",
    "    augment_rtt,\n",
    "    packet_loss,\n",
    ")\n",
    "\n",
    "# set working dir to correct folder\n",
    "os.chdir('/workplace/xcocek00/flowpics/')\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "# sets csv limit\n",
    "import csv\n",
    "import sys\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d56d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flowpic_to_img(tensor, filename, index=0, upscale=16, border=4):\n",
    "    '''\n",
    "    Converts FlowPic into upscaled grayscale image.\n",
    "\n",
    "    Args:\n",
    "        tensor: tensor of shape [batch_size, 1, H, W]\n",
    "        index: index of the FlowPic within the batch to save\n",
    "        filename: path where the output will be stored\n",
    "        upscale: factor to upscale the original FlowPic resolution\n",
    "    '''\n",
    "\n",
    "    # tensor -> np\n",
    "    arr = tensor[index].squeeze().cpu().numpy()\n",
    "\n",
    "    # Optional: enhance contrast using log scale\n",
    "    arr = np.log1p(arr)\n",
    "\n",
    "    # normalize to 0–255\n",
    "    arr = arr / arr.max() if arr.max() > 0 else arr\n",
    "    arr = (1 - arr) * 255  # 0 -> white, max -> black\n",
    "\n",
    "    img = Image.fromarray(arr.astype(np.uint8), mode='L')\n",
    "\n",
    "    # resize\n",
    "    new_size = (img.width * upscale, img.height * upscale)\n",
    "    img = img.resize(new_size, resample=Image.NEAREST)\n",
    "\n",
    "    img = ImageOps.expand(img, border=border, fill='black')\n",
    "\n",
    "    img.save(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a362fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(fp, upscale, border=4):\n",
    "    '''\n",
    "    Process flowpic to visual reprezentation\n",
    "\n",
    "    Args:\n",
    "        fp: flowpic tensor\n",
    "        upscale: the upscale factor\n",
    "        border: border around final img\n",
    "\n",
    "    Returns:\n",
    "        final img\n",
    "    \n",
    "    '''\n",
    "    arr = fp.squeeze().cpu().numpy()\n",
    "    arr = np.log1p(arr)\n",
    "    arr = arr / arr.max() if arr.max() > 0 else arr\n",
    "    arr = (1 - arr) * 255\n",
    "    \n",
    "    img = Image.fromarray(arr.astype(np.uint8), mode='L')\n",
    "    img = img.resize((img.width * upscale, img.height * upscale), resample=Image.NEAREST)\n",
    "    img = ImageOps.expand(img, border=border, fill='black')\n",
    "    \n",
    "    return img\n",
    "\n",
    "def combine_flowpics_to_img(tensor_orig, tensor_aug, filename, index=0, index2=0, upscale=16, gap=10):\n",
    "    '''\n",
    "    Combines original and augmented FlowPic from into single\n",
    "    side-by-side upscaled grayscale image.\n",
    "\n",
    "    Args:\n",
    "        tensor_orig: original FlowPics\n",
    "        tensor_aug:  augmented FlowPics\n",
    "        filename: path where the output will be stored\n",
    "        index: index of the FlowPic within the batch to save\n",
    "        index2: index of the second FlowPic within the batch to save\n",
    "        upscale: factor to upscale the original FlowPic resolution\n",
    "        gap: gap between 2 imgs\n",
    "    '''\n",
    "\n",
    "    img_orig = process(tensor_orig[index], upscale)\n",
    "    img_aug  = process(tensor_aug[index2], upscale)\n",
    "\n",
    "    # Calculate combined size with gap\n",
    "    width = img_orig.width + gap + img_aug.width\n",
    "    height = max(img_orig.height, img_aug.height)\n",
    "\n",
    "    combined = Image.new('L', (width, height), color='white')\n",
    "    combined.paste(img_orig, (0, 0))\n",
    "    combined.paste(img_aug, (img_orig.width + gap, 0))\n",
    "\n",
    "    combined.save(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfe858",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "FlowPics are created from the Ucdavis-icdm19 dataset, as it achieved the best performance according to my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51e52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO AUGMENTATION\n",
    "\n",
    "dl_orig = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "# one FlowPic only\n",
    "for fp1_orig, _, _ in dl_orig:\n",
    "    flowpic_to_img(tensor=fp1_orig, filename=\"flowpic_no_augmentation.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a784e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTT augmentation\n",
    "\n",
    "dl = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    flow_transform_1=augment_rtt,\n",
    "    flow_transform_2=augment_rtt,\n",
    ")\n",
    "\n",
    "# one FlowPic only\n",
    "for fp1, _, _ in dl:\n",
    "    flowpic_to_img(tensor=fp1, filename=\"flowpic_rtt.png\")\n",
    "    combine_flowpics_to_img(tensor_orig=fp1_orig, tensor_aug=fp1, filename=\"rtt_and_orig.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4e6df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IAT augmentation\n",
    "\n",
    "dl = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    flow_transform_1=augment_iat,\n",
    "    flow_transform_2=augment_iat,\n",
    ")\n",
    "\n",
    "# one FlowPic only\n",
    "for fp1, _, _ in dl:\n",
    "    flowpic_to_img(tensor=fp1, filename=\"flowpic_iat.png\")\n",
    "    combine_flowpics_to_img(tensor_orig=fp1_orig, tensor_aug=fp1, filename=\"iat_and_orig.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab301c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packet loss augmentation\n",
    "\n",
    "dl = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    flow_transform_1=packet_loss,\n",
    "    flow_transform_2=packet_loss,\n",
    ")\n",
    "\n",
    "# one FlowPic only\n",
    "for fp1, _, _ in dl:\n",
    "    flowpic_to_img(tensor=fp1, filename=\"flowpic_pkts_loss.png\")\n",
    "    combine_flowpics_to_img(tensor_orig=fp1_orig, tensor_aug=fp1, filename=\"pktl_and_orig.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb9edc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/common.py:145: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# FlowPic rotation\n",
    "\n",
    "dl = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "# one FlowPic only\n",
    "for fp1, _, _ in dl:\n",
    "    rotate_transform = T.RandomRotation(degrees=(-10,10))\n",
    "    if fp1.dim() == 4:\n",
    "        new_fp = torch.stack([rotate_transform(img) for img in fp1])\n",
    "\n",
    "    flowpic_to_img(tensor=new_fp, filename=\"flowpic_rotation.png\")\n",
    "    combine_flowpics_to_img(tensor_orig=fp1_orig, tensor_aug=new_fp, filename=\"rotation_and_orig.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384eaee6",
   "metadata": {},
   "source": [
    "### FlowPics per dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e036d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Mirage19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65188ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/common.py:145: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 2 FlowPics from Mirage19 dataset\n",
    "\n",
    "dl_m19 = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage19/processed/splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "f_dl_m19 = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage19/processed/splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    min_packets = 30,\n",
    ")\n",
    "\n",
    "for fp1, _, _ in dl_m19:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=4, filename=\"m19_flowpics.png\")\n",
    "    break\n",
    "\n",
    "for fp1, _, _ in f_dl_m19:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=4, filename=\"f_m19_flowpics.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34007c3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Mirage22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6113a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 FlowPics from Mirage22 dataset\n",
    "\n",
    "dl_m22 = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage22/processed/splits-10/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    min_packets = 10,\n",
    ")\n",
    "\n",
    "f_dl_m22 = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/mirage22/processed/splits-1000/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"BF_label\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    min_packets = 1000,\n",
    ")\n",
    "\n",
    "for fp1, _, _ in dl_m22:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=3, filename=\"10_m22_flowpics.png\")\n",
    "    break\n",
    "\n",
    "for fp1, _, _ in f_dl_m22:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=3, filename=\"1000_m22_flowpics.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21351e45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Ucdavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5a8209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlowPics from Ucdavis dataset\n",
    "\n",
    "train_dl_ucd = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/pretraining.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "script_dl_ucd = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/script.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "human_dl_ucd = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/ucdavis/final-splits/human.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "for fp1, _, _ in train_dl_ucd:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=4, filename=\"ucd_flowpics.png\")\n",
    "    break\n",
    "\n",
    "for fp1, _, _ in script_dl_ucd:\n",
    "    for fp2, _, _ in human_dl_ucd:\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp2, filename=\"script_human_flowpics.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44f2d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### UTMobileNet21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ca4356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlowPics from UTMobileNet dataset\n",
    "\n",
    "dl_utm = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/utmobilenet21/final-splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "f_dl_utm = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/datasets/utmobilenet21/final-splits/train.csv\",\n",
    "    batch_size=32,\n",
    "    meta_key=\"app\",    \n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    "    min_packets = 30,\n",
    ")\n",
    "\n",
    "for fp1, _, _ in dl_utm:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=4, filename=\"utm_flowpics.png\")\n",
    "    break\n",
    "\n",
    "for fp1, _, _ in f_dl_utm:\n",
    "    combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=4, filename=\"f_utm_flowpics.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c7cfae",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### CESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "055b8251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/torch/utils/data/datapipes/utils/common.py:145: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# FlowPics from CESNET dataset\n",
    "\n",
    "dl_ces = create_flowpic_dataloader(\n",
    "    dir_path=\"/workplace/data/long-export/tls-pstats100/tmp_balanced/train_group_c_timestamps.csv\",\n",
    "    batch_size=32,   \n",
    "    meta_key = \"label\",\n",
    "    time_bins = [i * (15 / 32) for i in range(33)],\n",
    "    length_bins = [i * (1500 / 32) for i in range(33)],\n",
    "    bidirectional = False,\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for fp1, _, _ in dl_ces:\n",
    "    if i == 0:\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=20, index2=30, filename=\"cesnet_flowpics1.png\")\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=14, filename=\"cesnet_flowpics2.png\")\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=10, index2=4, filename=\"cesnet_flowpics3.png\")\n",
    "    if i == 1:\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=2, index2=23, filename=\"cesnet_flowpics4.png\")\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=0, index2=7, filename=\"cesnet_flowpics5.png\")\n",
    "        combine_flowpics_to_img(tensor_orig=fp1, tensor_aug=fp1, index=1, index2=11, filename=\"cesnet_flowpics6.png\")\n",
    "        break\n",
    "                \n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
